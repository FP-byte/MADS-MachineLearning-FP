{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Hypertuning 1D CNN\n",
    "Study the pytorch documentation for:\n",
    "- Dropout https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html\n",
    "- normalization layers https://pytorch.org/docs/stable/nn.html#normalization-layers\n",
    "\n",
    "Experiment with adding dropout and normalization layers to your model. Some rough guidelines where to add them relative to Linear or Conv2d layers:\n",
    "- Dropout: after Linear or Conv2d layers. Often added after the last Linear layer *before* the output layer, but could occur more often.\n",
    "- Normalization layers: right after (blocks of) Linear or Conv2d layers, but before activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from loguru import logger\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetType.FLOWERS\n",
      "DatasetType.IMDB\n",
      "DatasetType.GESTURES\n",
      "DatasetType.FASHION\n",
      "DatasetType.SUNSPOTS\n",
      "DatasetType.IRIS\n",
      "DatasetType.PENGUINS\n",
      "DatasetType.FAVORITA\n",
      "DatasetType.SECURE\n"
     ]
    }
   ],
   "source": [
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "from mltrainer.preprocessors import BasePreprocessor\n",
    "\n",
    "for dataset in DatasetType:\n",
    "    print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-13 13:32:01.338\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at C:\\Users\\Francesca\\.cache\\mads_datasets\\gestures\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████████████████████████████████████████████████████████████████████████████████████████\u001b[0m| 2600/2600 [00:01<00:00, 1372.77it/s]\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m████████████████████████████████████████████████████████████████████████████████████████████████\u001b[0m| 651/651 [00:00<00:00, 1439.42it/s]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "from mltrainer.preprocessors import PaddedPreprocessor\n",
    "preprocessor = PaddedPreprocessor()\n",
    "\n",
    "gesturesfactory = DatasetFactoryProvider.create_factory(DatasetType.GESTURES)\n",
    "streamers = gesturesfactory.create_datastreamer(batchsize=32, preprocessor=preprocessor)\n",
    "train = streamers[\"train\"]\n",
    "valid = streamers[\"valid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-13 16:22:29.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at C:\\Users\\Francesca\\.cache\\mads_datasets\\flowers\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "from mltrainer.preprocessors import PaddedPreprocessor\n",
    "preprocessor = PaddedPreprocessor()\n",
    "\n",
    "gesturesfactory = DatasetFactoryProvider.create_factory(DatasetType.FLOWERS)\n",
    "streamers = gesturesfactory.create_datastreamer(batchsize=32, preprocessor=preprocessor)\n",
    "train = streamers[\"train\"]\n",
    "valid = streamers[\"valid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 22)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 224, 224]), torch.Size([32]))"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainstreamer = train.stream()\n",
    "validstreamer = valid.stream()\n",
    "x, y = next(iter(trainstreamer))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the 1D CNN model with one convolutional layer\n",
    "class Gesture1DCNN(nn.Module):\n",
    "    def __init__(self, input_channels=3, filters=64, units1=128, units2=64, num_classes=20):\n",
    "        super(Gesture1DCNN, self).__init__()\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            # Firs convolutional layer\n",
    "            nn.Conv1d(in_channels=input_channels, out_channels=filters, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            # Second convolutional layer\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(in_channels=filters, out_channels=filters*2, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            # Third convolutional layer (optional)\n",
    "            nn.Conv1d(in_channels=filters*2, out_channels=filters*4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.agg =  nn.AdaptiveMaxPool1d(1)  # Global max pooling reduces each feature map to a single value\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(filters*4, units1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(units1, units2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(units2, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # Now the shape is (batch_size, 3, 30)\n",
    "        x = self.convolutions(x) \n",
    "        x = self.agg(x)\n",
    "        # Remove the last dimension (sequence length is 1) for fully connected layer\n",
    "        x = x.view(x.size(0), -1)  # Flatten to (batch_size, 64)\n",
    "        logits = self.dense(x)\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gesture1DCNN(\n",
      "  (convolutions): Sequential(\n",
      "    (0): Conv1d(3, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (agg): AdaptiveMaxPool1d(output_size=1)\n",
      "  (dense): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=64, out_features=20, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 4 is not equal to len(dims) = 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[227], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Print model summary\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[1;32m---> 10\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# Should be (32, num_classes) — batch size x number of classes\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\osint\\code_repo\\AI\\MADS-MachineLearning-FP\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Documents\\osint\\code_repo\\AI\\MADS-MachineLearning-FP\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[226], line 37\u001b[0m, in \u001b[0;36mGesture1DCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 37\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Now the shape is (batch_size, 3, 30)\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvolutions(x) \n\u001b[0;32m     39\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg(x)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 4 is not equal to len(dims) = 3"
     ]
    }
   ],
   "source": [
    "\n",
    "input_channels = 3  # Number of input channels (e.g., x, y, z accelerometer data)\n",
    "num_classes = 20     # Number of gesture classes\n",
    "\n",
    "# Instantiate the model\n",
    "model = Gesture1DCNN()\n",
    "\n",
    "# Print model summary\n",
    "print(model)\n",
    "\n",
    "output = model(x)\n",
    "print(output.shape)  # Should be (32, num_classes) — batch size x number of classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the Naive 1D CNN model\n",
    "class Naive1DCNN(nn.Module):\n",
    "    def __init__(self, input_channels=3, filters=64, units1=128, num_classes=20):\n",
    "        super(Naive1DCNN, self).__init__()\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            # Firs convolutional layer\n",
    "            nn.Conv1d(in_channels=input_channels, out_channels=filters, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            # Second convolutional layer\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            \n",
    "        )\n",
    "\n",
    "        self.agg =  nn.AdaptiveMaxPool1d(1)  # Global max pooling reduces each feature map to a single value\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(filters, units1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(units1, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # Now the shape is (batch_size, 3, 30)\n",
    "        x = self.convolutions(x) \n",
    "        x = self.agg(x)\n",
    "        # Remove the last dimension (sequence length is 1) for fully connected layer\n",
    "        x = x.view(x.size(0), -1)  # Flatten to (batch_size, 64)\n",
    "        logits = self.dense(x)\n",
    "        return logits\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive1DCNN(\n",
      "  (convolutions): Sequential(\n",
      "    (0): Conv1d(3, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (agg): AdaptiveMaxPool1d(output_size=1)\n",
      "  (dense): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=20, bias=True)\n",
      "  )\n",
      ")\n",
      "torch.Size([32, 20])\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model_naive = Naive1DCNN()\n",
    "\n",
    "# Print model summary\n",
    "print(model_naive)\n",
    "\n",
    "output = model_naive(x)\n",
    "print(output.shape)  # Should be (32, num_classes) — batch size x number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from mltrainer import metrics, Trainer\n",
    "optimizer = optim.Adam\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "accuracy = metrics.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = Path(\"../../models/cnn\").resolve()\n",
    "if not log_dir.exists():\n",
    "    log_dir.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "epochs: 5\n",
       "metrics: [Accuracy]\n",
       "logdir: C:\\Users\\Francesca\\Documents\\osint\\code_repo\\AI\\MADS-MachineLearning-FP\\dev\\models\\cnn\n",
       "train_steps: 81\n",
       "valid_steps: 20\n",
       "reporttypes: [<ReportTypes.TENSORBOARD: 2>, <ReportTypes.MLFLOW: 3>]\n",
       "optimizer_kwargs: {'lr': 0.001, 'weight_decay': 1e-05}\n",
       "scheduler_kwargs: {'factor': 0.1, 'patience': 10}\n",
       "earlystop_kwargs: {'save': False, 'verbose': True, 'patience': 10}"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mltrainer import TrainerSettings, ReportTypes\n",
    "\n",
    "settings = TrainerSettings(\n",
    "    epochs=5,\n",
    "    metrics=[accuracy],\n",
    "    logdir=log_dir,\n",
    "    train_steps=len(train),\n",
    "    valid_steps=len(valid),\n",
    "    reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.MLFLOW],\n",
    ")\n",
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_path = \"mlflow_cnn1D-naive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "    print(\"using cuda\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"using cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-13 16:18:50.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to C:\\Users\\Francesca\\Documents\\osint\\code_repo\\AI\\MADS-MachineLearning-FP\\dev\\models\\cnn\\20241213-161850\u001b[0m\n",
      "\u001b[32m2024-12-13 16:18:50.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model_naive,\n",
    "    settings=settings,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    traindataloader=trainstreamer,\n",
    "    validdataloader=validstreamer,\n",
    "    scheduler=optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    device=device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[38;2;30;71;6m                                                                                                              \u001b[0m| 0/5 [00:00<?, ?it/s]\u001b[0m\n",
      "  0%|\u001b[38;2;30;71;6m                                                                                                             \u001b[0m| 0/81 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      " 12%|\u001b[38;2;30;71;6m████████████▎                                                                                       \u001b[0m| 10/81 [00:00<00:01, 56.94it/s]\u001b[0m\u001b[A\n",
      " 46%|\u001b[38;2;30;71;6m█████████████████████████████████████████████▏                                                     \u001b[0m| 37/81 [00:00<00:00, 151.03it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[38;2;30;71;6m███████████████████████████████████████████████████████████████████████████████████████████████████\u001b[0m| 81/81 [00:00<00:00, 194.54it/s]\u001b[0m\u001b[A\n",
      "\u001b[32m2024-12-13 16:18:52.954\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 2.4680 test 1.6984 metric ['0.6031']\u001b[0m\n",
      " 20%|\u001b[38;2;30;71;6m████████████████████▍                                                                                 \u001b[0m| 1/5 [00:00<00:02,  1.96it/s]\u001b[0m\n",
      "  0%|\u001b[38;2;30;71;6m                                                                                                             \u001b[0m| 0/81 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      " 40%|\u001b[38;2;30;71;6m███████████████████████████████████████                                                            \u001b[0m| 32/81 [00:00<00:00, 318.36it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[38;2;30;71;6m███████████████████████████████████████████████████████████████████████████████████████████████████\u001b[0m| 81/81 [00:00<00:00, 359.23it/s]\u001b[0m\u001b[A\n",
      "\u001b[32m2024-12-13 16:18:53.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 1.2187 test 0.8431 metric ['0.8328']\u001b[0m\n",
      " 40%|\u001b[38;2;30;71;6m████████████████████████████████████████▊                                                             \u001b[0m| 2/5 [00:00<00:01,  2.58it/s]\u001b[0m\n",
      "  0%|\u001b[38;2;30;71;6m                                                                                                             \u001b[0m| 0/81 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      " 48%|\u001b[38;2;30;71;6m███████████████████████████████████████████████▋                                                   \u001b[0m| 39/81 [00:00<00:00, 383.93it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[38;2;30;71;6m███████████████████████████████████████████████████████████████████████████████████████████████████\u001b[0m| 81/81 [00:00<00:00, 375.62it/s]\u001b[0m\u001b[A\n",
      "\u001b[32m2024-12-13 16:18:53.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.5974 test 0.5177 metric ['0.8891']\u001b[0m\n",
      " 60%|\u001b[38;2;30;71;6m█████████████████████████████████████████████████████████████▏                                        \u001b[0m| 3/5 [00:01<00:00,  2.68it/s]\u001b[0m\n",
      "  0%|\u001b[38;2;30;71;6m                                                                                                             \u001b[0m| 0/81 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      " 41%|\u001b[38;2;30;71;6m████████████████████████████████████████▎                                                          \u001b[0m| 33/81 [00:00<00:00, 323.37it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[38;2;30;71;6m███████████████████████████████████████████████████████████████████████████████████████████████████\u001b[0m| 81/81 [00:00<00:00, 349.77it/s]\u001b[0m\u001b[A\n",
      "\u001b[32m2024-12-13 16:18:53.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3692 test 0.3742 metric ['0.9000']\u001b[0m\n",
      " 80%|\u001b[38;2;30;71;6m█████████████████████████████████████████████████████████████████████████████████▌                    \u001b[0m| 4/5 [00:01<00:00,  2.86it/s]\u001b[0m\n",
      "  0%|\u001b[38;2;30;71;6m                                                                                                             \u001b[0m| 0/81 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      " 49%|\u001b[38;2;30;71;6m████████████████████████████████████████████████▉                                                  \u001b[0m| 40/81 [00:00<00:00, 399.76it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[38;2;30;71;6m███████████████████████████████████████████████████████████████████████████████████████████████████\u001b[0m| 81/81 [00:00<00:00, 339.80it/s]\u001b[0m\u001b[A\n",
      "\u001b[32m2024-12-13 16:18:54.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.2639 test 0.2789 metric ['0.9391']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████████████████████████████████████████████████████████████████████████████████████████████████\u001b[0m| 5/5 [00:01<00:00,  2.77it/s]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "trainer.loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use MLFLOW\n",
    "Start mlflow with:\n",
    "\n",
    "```\n",
    "mlflow server     --backend-store-uri sqlite:///mlflow.db     --default-artifact-root ./mlruns     --host 127.0.0.1:5000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope\n",
    "import mlflow\n",
    "import torch.optim as optim\n",
    "from mltrainer import metrics, Trainer, TrainerSettings, ReportTypes\n",
    "from datetime import datetime\n",
    "experiment_path = \"mlflow_test\"\n",
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "from mltrainer.preprocessors import BasePreprocessor\n",
    "from loguru import logger\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run intrigued-worm-231 at: http://127.0.0.1:5000/#/experiments/551708861503849523/runs/606d86c097bc481488e91bde12a12e15\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/551708861503849523\n"
     ]
    }
   ],
   "source": [
    "#end previous run\n",
    "mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-13 16:19:01.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at C:\\Users\\Francesca\\.cache\\mads_datasets\\gestures\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████████████████████████████████████████████████████████████████████████████████████████\u001b[0m| 2600/2600 [00:01<00:00, 2159.44it/s]\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m████████████████████████████████████████████████████████████████████████████████████████████████\u001b[0m| 651/651 [00:00<00:00, 2229.31it/s]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/551708861503849523', creation_time=1734100231912, experiment_id='551708861503849523', last_update_time=1734100231912, lifecycle_stage='active', name='mlflow_gestures1Dconv', tags={}>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_path = \"mlflow_gestures1Dconv\"\n",
    "gesturesfactory = DatasetFactoryProvider.create_factory(DatasetType.GESTURES)\n",
    "batchsize = 32\n",
    "preprocessor = PaddedPreprocessor()\n",
    "streamers = gesturesfactory.create_datastreamer(batchsize=batchsize, preprocessor=preprocessor)\n",
    "\n",
    "train = streamers[\"train\"]\n",
    "valid = streamers[\"valid\"]\n",
    "trainstreamer = train.stream()\n",
    "validstreamer = valid.stream()\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(experiment_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the hyperparameter search space\n",
    "settings = TrainerSettings(\n",
    "    epochs=3,\n",
    "    metrics=[accuracy],\n",
    "    logdir=\"modellog\",\n",
    "    train_steps=100,\n",
    "    valid_steps=100,\n",
    "    reporttypes=[ReportTypes.MLFLOW],\n",
    ")\n",
    "\n",
    "\n",
    "# Define the objective function for hyperparameter optimization\n",
    "def objective(params):\n",
    "    # Start a new MLflow run for tracking the experiment\n",
    "    with mlflow.start_run():\n",
    "        # Set MLflow tags to record metadata about the model and developer\n",
    "        mlflow.set_tag(\"model\", \"convnet\")\n",
    "        mlflow.set_tag(\"dev\", \"fp\")\n",
    "        # Log hyperparameters to MLflow\n",
    "        mlflow.log_params(params)\n",
    "        print(params)\n",
    "        mlflow.log_param(\"batchsize\", f\"{batchsize}\")\n",
    "\n",
    "\n",
    "        # Initialize the optimizer, loss function, and accuracy metric\n",
    "        optimizer = optim.Adam\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        accuracy = metrics.Accuracy()\n",
    "\n",
    "        # Instantiate the CNN model with the given hyperparameters\n",
    "        model = Gesture1DCNN(**params)\n",
    "        # Train the model using a custom train loop\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            settings=settings,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            traindataloader=trainstreamer,\n",
    "            validdataloader=validstreamer,\n",
    "            scheduler=optim.lr_scheduler.ReduceLROnPlateau,\n",
    "            device=device,\n",
    "        )\n",
    "        trainer.loop()\n",
    "\n",
    "        # Save the trained model with a timestamp\n",
    "        tag = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "        modelpath = modeldir / (tag + \"model.pt\")\n",
    "        torch.save(model, modelpath)\n",
    "\n",
    "        # Log the saved model as an artifact in MLflow\n",
    "        mlflow.log_artifact(local_path=modelpath, artifact_path=\"pytorch_models\")\n",
    "        return {'loss' : trainer.test_loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_space = {\n",
    "#     'filters' : scope.int(hp.quniform('filters', 16, 128, 8)),\n",
    "#     'units1' : scope.int(hp.quniform('units1', 32, 128, 8)),\n",
    "#     'units2' : scope.int(hp.quniform('units2', 32, 128, 8)),\n",
    "# }\n",
    "search_space = {\n",
    "     'filters' : scope.int(hp.quniform('filters', 16, 128, 8)),\n",
    "     'units1' : scope.int(hp.quniform('units1', 32, 256, 8)),\n",
    "     'units2' : scope.int(hp.quniform('units2', 32, 256, 8)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filters': 88, 'units1': 232, 'units2': 176}                                                                                            \n",
      "  0%|                                                                                              | 0/5 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-13 16:19:13.205\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellog\\20241213-161913\u001b[0m\n",
      "\u001b[32m2024-12-13 16:19:13.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "  0%|\u001b[38;2;30;71;6m                                                                                                              \u001b[0m| 0/3 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[A\n",
      "  0%|\u001b[38;2;30;71;6m                                                                                                            \u001b[0m| 0/100 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      "  1%|\u001b[38;2;30;71;6m#                                                                                                   \u001b[0m| 1/100 [00:00<00:10,  9.30it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      "  2%|\u001b[38;2;30;71;6m##                                                                                                  \u001b[0m| 2/100 [00:00<00:10,  8.95it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 17%|\u001b[38;2;30;71;6m################8                                                                                  \u001b[0m| 17/100 [00:00<00:01, 69.10it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 37%|\u001b[38;2;30;71;6m####################################2                                                             \u001b[0m| 37/100 [00:00<00:00, 117.78it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 59%|\u001b[38;2;30;71;6m#########################################################8                                        \u001b[0m| 59/100 [00:00<00:00, 151.17it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 79%|\u001b[38;2;30;71;6m#############################################################################4                    \u001b[0m| 79/100 [00:00<00:00, 166.88it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      "100%|\u001b[38;2;30;71;6m#################################################################################################\u001b[0m| 100/100 [00:00<00:00, 137.05it/s]\u001b[0m\n",
      "\u001b[32m2024-12-13 16:19:14.208\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 1.4033 test 0.3423 metric ['0.8688']\u001b[0m\n",
      " 33%|\u001b[38;2;30;71;6m##################################                                                                    \u001b[0m| 1/3 [00:00<00:01,  1.02it/s]\u001b[0m\n",
      "\u001b[A\n",
      "  0%|\u001b[38;2;30;71;6m                                                                                                            \u001b[0m| 0/100 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 21%|\u001b[38;2;30;71;6m####################5                                                                             \u001b[0m| 21/100 [00:00<00:00, 207.92it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 42%|\u001b[38;2;30;71;6m#########################################1                                                        \u001b[0m| 42/100 [00:00<00:00, 201.93it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 64%|\u001b[38;2;30;71;6m##############################################################7                                   \u001b[0m| 64/100 [00:00<00:00, 206.42it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 85%|\u001b[38;2;30;71;6m###################################################################################3              \u001b[0m| 85/100 [00:00<00:00, 206.98it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      "100%|\u001b[38;2;30;71;6m#################################################################################################\u001b[0m| 100/100 [00:00<00:00, 207.66it/s]\u001b[0m\n",
      "\u001b[32m2024-12-13 16:19:14.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.1705 test 0.1111 metric ['0.9666']\u001b[0m\n",
      " 67%|\u001b[38;2;30;71;6m####################################################################                                  \u001b[0m| 2/3 [00:01<00:00,  1.22it/s]\u001b[0m\n",
      "\u001b[A\n",
      "  0%|\u001b[38;2;30;71;6m                                                                                                            \u001b[0m| 0/100 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 25%|\u001b[38;2;30;71;6m########################5                                                                         \u001b[0m| 25/100 [00:00<00:00, 244.97it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 50%|\u001b[38;2;30;71;6m#################################################                                                 \u001b[0m| 50/100 [00:00<00:00, 241.38it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 75%|\u001b[38;2;30;71;6m#########################################################################5                        \u001b[0m| 75/100 [00:00<00:00, 243.08it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      "100%|\u001b[38;2;30;71;6m#################################################################################################\u001b[0m| 100/100 [00:00<00:00, 244.76it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      "100%|\u001b[38;2;30;71;6m#################################################################################################\u001b[0m| 100/100 [00:00<00:00, 243.49it/s]\u001b[0m\n",
      "\u001b[32m2024-12-13 16:19:15.554\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.0794 test 0.1553 metric ['0.9631']\u001b[0m\n",
      "\u001b[32m2024-12-13 16:19:15.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.1111, current loss 0.1553.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m######################################################################################################\u001b[0m| 3/3 [00:02<00:00,  1.35it/s]\u001b[0m\n",
      "\u001b[A\n",
      "100%|\u001b[38;2;30;71;6m######################################################################################################\u001b[0m| 3/3 [00:02<00:00,  1.29it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run glamorous-worm-441 at: http://127.0.0.1:5000/#/experiments/551708861503849523/runs/2ee1a3f446dd45e4811283a0060bb405          \n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/551708861503849523                                                            \n",
      "\n",
      "{'filters': 64, 'units1': 128, 'units2': 144}                                                                                            \n",
      " 20%|█████████████▊                                                       | 1/5 [00:02<00:10,  2.59s/trial, best loss: 0.155273899435997]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-13 16:19:15.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellog\\20241213-161915\u001b[0m\n",
      "\u001b[32m2024-12-13 16:19:15.770\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "  0%|\u001b[38;2;30;71;6m                                                                                                              \u001b[0m| 0/3 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[A\n",
      "  0%|\u001b[38;2;30;71;6m                                                                                                            \u001b[0m| 0/100 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 24%|\u001b[38;2;30;71;6m#######################5                                                                          \u001b[0m| 24/100 [00:00<00:00, 237.57it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 48%|\u001b[38;2;30;71;6m###############################################                                                   \u001b[0m| 48/100 [00:00<00:00, 238.95it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 74%|\u001b[38;2;30;71;6m########################################################################5                         \u001b[0m| 74/100 [00:00<00:00, 246.02it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 99%|\u001b[38;2;30;71;6m################################################################################################# \u001b[0m| 99/100 [00:00<00:00, 240.68it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      "100%|\u001b[38;2;30;71;6m#################################################################################################\u001b[0m| 100/100 [00:00<00:00, 239.43it/s]\u001b[0m\n",
      "\u001b[32m2024-12-13 16:19:16.404\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 1.5588 test 0.5409 metric ['0.8116']\u001b[0m\n",
      " 33%|\u001b[38;2;30;71;6m##################################                                                                    \u001b[0m| 1/3 [00:00<00:01,  1.58it/s]\u001b[0m\n",
      "\u001b[A\n",
      "  0%|\u001b[38;2;30;71;6m                                                                                                            \u001b[0m| 0/100 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 24%|\u001b[38;2;30;71;6m#######################5                                                                          \u001b[0m| 24/100 [00:00<00:00, 239.15it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 49%|\u001b[38;2;30;71;6m################################################                                                  \u001b[0m| 49/100 [00:00<00:00, 242.59it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 74%|\u001b[38;2;30;71;6m########################################################################5                         \u001b[0m| 74/100 [00:00<00:00, 242.02it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 99%|\u001b[38;2;30;71;6m################################################################################################# \u001b[0m| 99/100 [00:00<00:00, 241.35it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      "100%|\u001b[38;2;30;71;6m#################################################################################################\u001b[0m| 100/100 [00:00<00:00, 238.65it/s]\u001b[0m\n",
      "\u001b[32m2024-12-13 16:19:17.042\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.2751 test 0.1832 metric ['0.9519']\u001b[0m\n",
      " 67%|\u001b[38;2;30;71;6m####################################################################                                  \u001b[0m| 2/3 [00:01<00:00,  1.57it/s]\u001b[0m\n",
      "\u001b[A\n",
      "  0%|\u001b[38;2;30;71;6m                                                                                                            \u001b[0m| 0/100 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 15%|\u001b[38;2;30;71;6m##############7                                                                                   \u001b[0m| 15/100 [00:00<00:00, 139.51it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 33%|\u001b[38;2;30;71;6m################################3                                                                 \u001b[0m| 33/100 [00:00<00:00, 159.45it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 56%|\u001b[38;2;30;71;6m######################################################8                                           \u001b[0m| 56/100 [00:00<00:00, 188.26it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 80%|\u001b[38;2;30;71;6m##############################################################################4                   \u001b[0m| 80/100 [00:00<00:00, 207.36it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      "100%|\u001b[38;2;30;71;6m#################################################################################################\u001b[0m| 100/100 [00:00<00:00, 198.58it/s]\u001b[0m\n",
      "\u001b[32m2024-12-13 16:19:17.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.1276 test 0.1142 metric ['0.9684']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m######################################################################################################\u001b[0m| 3/3 [00:01<00:00,  1.49it/s]\u001b[0m\n",
      "\u001b[A\n",
      "100%|\u001b[38;2;30;71;6m######################################################################################################\u001b[0m| 3/3 [00:01<00:00,  1.51it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run unique-turtle-57 at: http://127.0.0.1:5000/#/experiments/551708861503849523/runs/a2351b2fec5c45d897886afa009458be            \n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/551708861503849523                                                            \n",
      "\n",
      "{'filters': 120, 'units1': 192, 'units2': 40}                                                                                            \n",
      " 40%|██████████████████████████▊                                        | 2/5 [00:04<00:07,  2.35s/trial, best loss: 0.11422119289636612]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-13 16:19:17.952\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellog\\20241213-161917\u001b[0m\n",
      "\u001b[32m2024-12-13 16:19:17.955\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "  0%|\u001b[38;2;30;71;6m                                                                                                              \u001b[0m| 0/3 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[A\n",
      "  0%|\u001b[38;2;30;71;6m                                                                                                            \u001b[0m| 0/100 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 20%|\u001b[38;2;30;71;6m###################6                                                                              \u001b[0m| 20/100 [00:00<00:00, 193.01it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 42%|\u001b[38;2;30;71;6m#########################################1                                                        \u001b[0m| 42/100 [00:00<00:00, 207.26it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 65%|\u001b[38;2;30;71;6m###############################################################7                                  \u001b[0m| 65/100 [00:00<00:00, 217.47it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 90%|\u001b[38;2;30;71;6m########################################################################################2         \u001b[0m| 90/100 [00:00<00:00, 229.30it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      "100%|\u001b[38;2;30;71;6m#################################################################################################\u001b[0m| 100/100 [00:00<00:00, 224.03it/s]\u001b[0m\n",
      "\u001b[32m2024-12-13 16:19:18.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 1.4262 test 0.4804 metric ['0.8337']\u001b[0m\n",
      " 33%|\u001b[38;2;30;71;6m##################################                                                                    \u001b[0m| 1/3 [00:00<00:01,  1.51it/s]\u001b[0m\n",
      "\u001b[A\n",
      "  0%|\u001b[38;2;30;71;6m                                                                                                            \u001b[0m| 0/100 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 25%|\u001b[38;2;30;71;6m########################5                                                                         \u001b[0m| 25/100 [00:00<00:00, 246.19it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 50%|\u001b[38;2;30;71;6m#################################################                                                 \u001b[0m| 50/100 [00:00<00:00, 245.35it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 76%|\u001b[38;2;30;71;6m##########################################################################4                       \u001b[0m| 76/100 [00:00<00:00, 248.72it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      "100%|\u001b[38;2;30;71;6m#################################################################################################\u001b[0m| 100/100 [00:00<00:00, 248.37it/s]\u001b[0m\n",
      "\u001b[32m2024-12-13 16:19:19.239\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.1707 test 0.1527 metric ['0.9569']\u001b[0m\n",
      " 67%|\u001b[38;2;30;71;6m####################################################################                                  \u001b[0m| 2/3 [00:01<00:00,  1.57it/s]\u001b[0m\n",
      "\u001b[A\n",
      "  0%|\u001b[38;2;30;71;6m                                                                                                            \u001b[0m| 0/100 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 25%|\u001b[38;2;30;71;6m########################5                                                                         \u001b[0m| 25/100 [00:00<00:00, 248.53it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 50%|\u001b[38;2;30;71;6m#################################################                                                 \u001b[0m| 50/100 [00:00<00:00, 244.48it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 75%|\u001b[38;2;30;71;6m#########################################################################5                        \u001b[0m| 75/100 [00:00<00:00, 245.22it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      "100%|\u001b[38;2;30;71;6m#################################################################################################\u001b[0m| 100/100 [00:00<00:00, 241.41it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      "100%|\u001b[38;2;30;71;6m#################################################################################################\u001b[0m| 100/100 [00:00<00:00, 241.77it/s]\u001b[0m\n",
      "\u001b[32m2024-12-13 16:19:19.868\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.1000 test 0.1299 metric ['0.9703']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m######################################################################################################\u001b[0m| 3/3 [00:01<00:00,  1.58it/s]\u001b[0m\n",
      "\u001b[A\n",
      "100%|\u001b[38;2;30;71;6m######################################################################################################\u001b[0m| 3/3 [00:01<00:00,  1.57it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run beautiful-dove-171 at: http://127.0.0.1:5000/#/experiments/551708861503849523/runs/c79e0967233e4b749f8cf09b144f232d          \n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/551708861503849523                                                            \n",
      "\n",
      "{'filters': 88, 'units1': 224, 'units2': 168}                                                                                            \n",
      " 60%|████████████████████████████████████████▏                          | 3/5 [00:06<00:04,  2.24s/trial, best loss: 0.11422119289636612]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-13 16:19:20.063\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellog\\20241213-161920\u001b[0m\n",
      "\u001b[32m2024-12-13 16:19:20.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "  0%|\u001b[38;2;30;71;6m                                                                                                              \u001b[0m| 0/3 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[A\n",
      "  0%|\u001b[38;2;30;71;6m                                                                                                            \u001b[0m| 0/100 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 25%|\u001b[38;2;30;71;6m########################5                                                                         \u001b[0m| 25/100 [00:00<00:00, 248.38it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 51%|\u001b[38;2;30;71;6m#################################################9                                                \u001b[0m| 51/100 [00:00<00:00, 253.57it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 79%|\u001b[38;2;30;71;6m#############################################################################4                    \u001b[0m| 79/100 [00:00<00:00, 265.45it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      "100%|\u001b[38;2;30;71;6m#################################################################################################\u001b[0m| 100/100 [00:00<00:00, 261.15it/s]\u001b[0m\n",
      "\u001b[32m2024-12-13 16:19:20.679\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 1.2982 test 0.3734 metric ['0.8756']\u001b[0m\n",
      " 33%|\u001b[38;2;30;71;6m##################################                                                                    \u001b[0m| 1/3 [00:00<00:01,  1.64it/s]\u001b[0m\n",
      "\u001b[A\n",
      "  0%|\u001b[38;2;30;71;6m                                                                                                            \u001b[0m| 0/100 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 24%|\u001b[38;2;30;71;6m#######################5                                                                          \u001b[0m| 24/100 [00:00<00:00, 232.89it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 50%|\u001b[38;2;30;71;6m#################################################                                                 \u001b[0m| 50/100 [00:00<00:00, 246.64it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 78%|\u001b[38;2;30;71;6m############################################################################4                     \u001b[0m| 78/100 [00:00<00:00, 259.26it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      "100%|\u001b[38;2;30;71;6m#################################################################################################\u001b[0m| 100/100 [00:00<00:00, 255.70it/s]\u001b[0m\n",
      "\u001b[32m2024-12-13 16:19:21.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.1406 test 0.1947 metric ['0.9375']\u001b[0m\n",
      " 67%|\u001b[38;2;30;71;6m####################################################################                                  \u001b[0m| 2/3 [00:01<00:00,  1.62it/s]\u001b[0m\n",
      "\u001b[A\n",
      "  0%|\u001b[38;2;30;71;6m                                                                                                            \u001b[0m| 0/100 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 25%|\u001b[38;2;30;71;6m########################5                                                                         \u001b[0m| 25/100 [00:00<00:00, 247.50it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 52%|\u001b[38;2;30;71;6m##################################################9                                               \u001b[0m| 52/100 [00:00<00:00, 259.06it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 78%|\u001b[38;2;30;71;6m############################################################################4                     \u001b[0m| 78/100 [00:00<00:00, 244.99it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      "100%|\u001b[38;2;30;71;6m#################################################################################################\u001b[0m| 100/100 [00:00<00:00, 247.41it/s]\u001b[0m\n",
      "\u001b[32m2024-12-13 16:19:21.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.0732 test 0.0694 metric ['0.9838']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m######################################################################################################\u001b[0m| 3/3 [00:01<00:00,  1.63it/s]\u001b[0m\n",
      "\u001b[A\n",
      "100%|\u001b[38;2;30;71;6m######################################################################################################\u001b[0m| 3/3 [00:01<00:00,  1.62it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run fortunate-cod-256 at: http://127.0.0.1:5000/#/experiments/551708861503849523/runs/b44d87305c8048d397988b5f76b1d6f7           \n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/551708861503849523                                                            \n",
      "\n",
      "{'filters': 80, 'units1': 176, 'units2': 248}                                                                                            \n",
      " 80%|█████████████████████████████████████████████████████▌             | 4/5 [00:09<00:02,  2.16s/trial, best loss: 0.06940709054470062]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-13 16:19:22.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to modellog\\20241213-161922\u001b[0m\n",
      "\u001b[32m2024-12-13 16:19:22.106\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "  0%|\u001b[38;2;30;71;6m                                                                                                              \u001b[0m| 0/3 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[A\n",
      "  0%|\u001b[38;2;30;71;6m                                                                                                            \u001b[0m| 0/100 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 25%|\u001b[38;2;30;71;6m########################5                                                                         \u001b[0m| 25/100 [00:00<00:00, 243.00it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 52%|\u001b[38;2;30;71;6m##################################################9                                               \u001b[0m| 52/100 [00:00<00:00, 254.22it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 80%|\u001b[38;2;30;71;6m##############################################################################4                   \u001b[0m| 80/100 [00:00<00:00, 263.18it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      "100%|\u001b[38;2;30;71;6m#################################################################################################\u001b[0m| 100/100 [00:00<00:00, 256.22it/s]\u001b[0m\n",
      "\u001b[32m2024-12-13 16:19:22.718\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 1.3409 test 0.4207 metric ['0.8569']\u001b[0m\n",
      " 33%|\u001b[38;2;30;71;6m##################################                                                                    \u001b[0m| 1/3 [00:00<00:01,  1.64it/s]\u001b[0m\n",
      "\u001b[A\n",
      "  0%|\u001b[38;2;30;71;6m                                                                                                            \u001b[0m| 0/100 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 23%|\u001b[38;2;30;71;6m######################5                                                                           \u001b[0m| 23/100 [00:00<00:00, 220.60it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 48%|\u001b[38;2;30;71;6m###############################################                                                   \u001b[0m| 48/100 [00:00<00:00, 237.44it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 74%|\u001b[38;2;30;71;6m########################################################################5                         \u001b[0m| 74/100 [00:00<00:00, 246.38it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      "100%|\u001b[38;2;30;71;6m#################################################################################################\u001b[0m| 100/100 [00:00<00:00, 247.73it/s]\u001b[0m\n",
      "\u001b[32m2024-12-13 16:19:23.333\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.2054 test 0.1886 metric ['0.9431']\u001b[0m\n",
      " 67%|\u001b[38;2;30;71;6m####################################################################                                  \u001b[0m| 2/3 [00:01<00:00,  1.63it/s]\u001b[0m\n",
      "\u001b[A\n",
      "  0%|\u001b[38;2;30;71;6m                                                                                                            \u001b[0m| 0/100 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 26%|\u001b[38;2;30;71;6m#########################4                                                                        \u001b[0m| 26/100 [00:00<00:00, 250.55it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 53%|\u001b[38;2;30;71;6m###################################################9                                              \u001b[0m| 53/100 [00:00<00:00, 259.56it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      " 79%|\u001b[38;2;30;71;6m#############################################################################4                    \u001b[0m| 79/100 [00:00<00:00, 250.85it/s]\u001b[0m\n",
      "\u001b[A\u001b[A\n",
      "100%|\u001b[38;2;30;71;6m#################################################################################################\u001b[0m| 100/100 [00:00<00:00, 254.66it/s]\u001b[0m\n",
      "\u001b[32m2024-12-13 16:19:23.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.0886 test 0.0862 metric ['0.9838']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m######################################################################################################\u001b[0m| 3/3 [00:01<00:00,  1.63it/s]\u001b[0m\n",
      "\u001b[A\n",
      "100%|\u001b[38;2;30;71;6m######################################################################################################\u001b[0m| 3/3 [00:01<00:00,  1.63it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run treasured-bat-808 at: http://127.0.0.1:5000/#/experiments/551708861503849523/runs/1084437040304a3cb4d203a17193a5b3           \n",
      "\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/551708861503849523                                                            \n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████| 5/5 [00:10<00:00,  2.19s/trial, best loss: 0.06940709054470062]\n"
     ]
    }
   ],
   "source": [
    "best_result = fmin(\n",
    "    fn=objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=5,\n",
    "    trials=Trials()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filters': np.float64(88.0),\n",
       " 'units1': np.float64(224.0),\n",
       " 'units2': np.float64(168.0)}"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filters': np.float64(112.0),\n",
       " 'units1': np.float64(72.0),\n",
       " 'units2': np.float64(120.0)}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filters': np.float64(104.0),\n",
       " 'units1': np.float64(120.0),\n",
       " 'units2': np.float64(120.0)}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Naive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
