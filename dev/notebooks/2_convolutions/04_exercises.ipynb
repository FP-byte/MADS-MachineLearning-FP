{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Adding dropout and normalization layers\n",
    "Study the pytorch documentation for:\n",
    "- Dropout https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html\n",
    "- normalization layers https://pytorch.org/docs/stable/nn.html#normalization-layers\n",
    "\n",
    "Experiment with adding dropout and normalization layers to your model. Some rough guidelines where to add them relative to Linear or Conv2d layers:\n",
    "- Dropout: after Linear or Conv2d layers. Often added after the last Linear layer *before* the output layer, but could occur more often.\n",
    "- Normalization layers: right after (blocks of) Linear or Conv2d layers, but before activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from loguru import logger\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetType.FLOWERS\n",
      "DatasetType.IMDB\n",
      "DatasetType.GESTURES\n",
      "DatasetType.FASHION\n",
      "DatasetType.SUNSPOTS\n",
      "DatasetType.IRIS\n",
      "DatasetType.PENGUINS\n",
      "DatasetType.FAVORITA\n",
      "DatasetType.SECURE\n"
     ]
    }
   ],
   "source": [
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "from mltrainer.preprocessors import BasePreprocessor\n",
    "\n",
    "for dataset in DatasetType:\n",
    "    print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-26 20:02:12.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mStart download...\u001b[0m\n",
      "  0%|\u001b[38;2;30;71;6m                                                                                      \u001b[0m| 0.00/229M [00:00<?, ?iB/s]\u001b[0m\u001b[32m2024-11-26 20:02:12.239\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.datatools\u001b[0m:\u001b[36mget_file\u001b[0m:\u001b[36m105\u001b[0m - \u001b[1mDownloading C:\\Users\\Francesca\\.cache\\mads_datasets\\flowers\\flowers.tgz\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████████████████████████████████████████████████████████████████████████\u001b[0m| 229M/229M [00:08<00:00, 26.4MiB/s]\u001b[0m\n",
      "\u001b[32m2024-11-26 20:02:20.922\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.datatools\u001b[0m:\u001b[36mextract\u001b[0m:\u001b[36m128\u001b[0m - \u001b[1mUnzipping C:\\Users\\Francesca\\.cache\\mads_datasets\\flowers\\flowers.tgz\u001b[0m\n",
      "\u001b[32m2024-11-26 20:02:28.494\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m112\u001b[0m - \u001b[1mDigest of C:\\Users\\Francesca\\.cache\\mads_datasets\\flowers\\flowers.tgz matches expected digest\u001b[0m\n",
      "\u001b[32m2024-11-26 20:02:28.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m117\u001b[0m - \u001b[1mRemoving unzipped file C:\\Users\\Francesca\\.cache\\mads_datasets\\flowers\\flowers.tgz\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "from mltrainer.preprocessors import BasePreprocessor\n",
    "preprocessor = BasePreprocessor()\n",
    "\n",
    "#fashionfactory = DatasetFactoryProvider.create_factory(DatasetType.FASHION)\n",
    "#streamers = fashionfactory.create_datastreamer(batchsize=64, preprocessor=preprocessor)\n",
    "flowersfactory = DatasetFactoryProvider.create_factory(DatasetType.FLOWERS)\n",
    "streamers = flowersfactory.create_datastreamer(batchsize=32, preprocessor=preprocessor)\n",
    "train = streamers[\"train\"]\n",
    "valid = streamers[\"valid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91, 22)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 224, 224]), torch.Size([32]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainstreamer = train.stream()\n",
    "validstreamer = valid.stream()\n",
    "x, y = next(iter(trainstreamer))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in_channels - RGB\n",
    "in_channels = x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from loguru import logger\n",
    "from torchsummary import summary\n",
    "import copy\n",
    "\n",
    "\n",
    "# Define model\n",
    "class CNN(nn.Module):\n",
    "    \"\"\"\n",
    "    filters: int, out_channels = number of kernels\n",
    "    units1: int, units for first linear Fully connected layer output\n",
    "    units2: int, units for second linear Fully connected layer output\n",
    "    input_size: tuple\n",
    "    \"\"\"\n",
    "    def __init__(self, filters: int, units1: int, units2: int, input_size: tuple):\n",
    "        super().__init__()\n",
    "        self.in_channels = input_size[1]\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.convolutions = nn.Sequential(\n",
    "            nn.Conv2d(self.in_channels, filters, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Conv2d(filters, filters, kernel_size=3, stride=1, padding=0),\n",
    "            \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(filters, filters, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "\n",
    "        activation_map_size = self._conv_test(self.input_size)\n",
    "        print(activation_map_size)\n",
    "        logger.info(f\"Aggregating activationmap with size {activation_map_size}\")\n",
    "        self.agg = nn.AvgPool2d(activation_map_size)\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(filters, units1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(units1, units2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(units2, 32)\n",
    "        )\n",
    "\n",
    "    def _conv_test(self, input_size):\n",
    "        x = torch.ones(input_size, dtype=torch.float32)\n",
    "        x = self.convolutions(x)\n",
    "        return x.shape[-2:]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convolutions(x)\n",
    "        x = self.agg(x)\n",
    "        logits = self.dense(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-26 21:12:37.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m37\u001b[0m - \u001b[1mAggregating activationmap with size torch.Size([26, 26])\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([26, 26])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1        [-1, 128, 224, 224]           3,584\n",
      "              ReLU-2        [-1, 128, 224, 224]               0\n",
      "         MaxPool2d-3        [-1, 128, 112, 112]               0\n",
      "           Dropout-4        [-1, 128, 112, 112]               0\n",
      "            Conv2d-5        [-1, 128, 110, 110]         147,584\n",
      "              ReLU-6        [-1, 128, 110, 110]               0\n",
      "         MaxPool2d-7          [-1, 128, 55, 55]               0\n",
      "            Conv2d-8          [-1, 128, 53, 53]         147,584\n",
      "              ReLU-9          [-1, 128, 53, 53]               0\n",
      "        MaxPool2d-10          [-1, 128, 26, 26]               0\n",
      "        AvgPool2d-11            [-1, 128, 1, 1]               0\n",
      "          Flatten-12                  [-1, 128]               0\n",
      "           Linear-13                  [-1, 128]          16,512\n",
      "             ReLU-14                  [-1, 128]               0\n",
      "           Linear-15                  [-1, 224]          28,896\n",
      "             ReLU-16                  [-1, 224]               0\n",
      "           Linear-17                   [-1, 32]           7,200\n",
      "================================================================\n",
      "Total params: 351,360\n",
      "Trainable params: 351,360\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 155.24\n",
      "Params size (MB): 1.34\n",
      "Estimated Total Size (MB): 157.16\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = CNN(filters=128, units1=128, units2=224, input_size=(32, 3, 224, 224))\n",
    "summary(model, input_size=(3, 224, 224), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Adding convolutional and pooling layers\n",
    "Previous lessons, you have started to experiment with you model.\n",
    "You might have tested the impact of the amount of units, the depth of layers and different learning rates.\n",
    "\n",
    "This lesson, we have added some new types of layers: convolutional and pooling layers.\n",
    "Experiment with adding these new layers.\n",
    "\n",
    "Also, have a look at the `ModuleList`: https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html#modulelist\n",
    "It can be really useful to create a list of layers from a configfile, and then use that list to create your model.\n",
    "Instead of just adding a single layer, you could also add a block of layers (eg a Conv2d layer, followed by a ReLU layer, followed by a BatchNorm2d layer, followed by a MaxPool2d layer) and repeat that in a loop, adding it to the `ModuleList`.\n",
    "\n",
    "# 3. Improve your pipeline\n",
    "In addition to new layers, we have expanded our logging tools with MLFlow, so we currently can choose between gin-config, tensorboard and MLFlow.\n",
    "\n",
    "Expand your training pipeline you started in the previous lesson such that:\n",
    "\n",
    "- you can switch between models by changing a config file\n",
    "- you can test different hyperparameters by changing a config file\n",
    "- you automatically log settings: model picked, hyperparameters, metrics, etc. : use either gin-config, tensorboard or MLFlow to log that, or a combination, whatever you prefer.\n",
    "- Important: doing a master means you don't just start engineering a pipeline, but you need to reflect. Why do you see the results you see? What does this mean, considering the theory? Write down lessons learned and reflections, based on experimental results.\n",
    "- continuously improve your code: \n",
    "    - clean up your experimental environment, such that it doesnt get too messy\n",
    "    - automate the boring stuff: use a Makefile, use configfiles, automate logging, etc.\n",
    "    - use git: commit your changes often and with descriptive messages\n",
    "    - separate code for pipelines, configs, models, modeltraining and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
